{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cca903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bandainamco-mirai/distilbert-base-japanese were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bandainamco-mirai/distilbert-base-japanese were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/jupyter/.cache/pypoetry/virtualenvs/template-for-ai-pytorch-lightning-njAqaEcn-py3.7/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Checkpoint directory /home/jupyter/ogawa_prediction/model/distil/2021-08-13/0 exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                     | Params\n",
      "-----------------------------------------------------------\n",
      "0 | model         | DistilBERTBaseClassifier | 67.5 M\n",
      "1 | loss_function | CrossEntropyLoss         | 0     \n",
      "2 | train_acc     | Accuracy                 | 0     \n",
      "3 | valid_acc     | Accuracy                 | 0     \n",
      "-----------------------------------------------------------\n",
      "67.1 M    Trainable params\n",
      "393 K     Non-trainable params\n",
      "67.5 M    Total params\n",
      "270.004   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.cache/pypoetry/virtualenvs/template-for-ai-pytorch-lightning-njAqaEcn-py3.7/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/jupyter/.cache/pypoetry/virtualenvs/template-for-ai-pytorch-lightning-njAqaEcn-py3.7/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11cd5b193dbc4258b515e55def801de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.cache/pypoetry/virtualenvs/template-for-ai-pytorch-lightning-njAqaEcn-py3.7/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Some weights of the model checkpoint at bandainamco-mirai/distilbert-base-japanese were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/jupyter/.cache/pypoetry/virtualenvs/template-for-ai-pytorch-lightning-njAqaEcn-py3.7/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Checkpoint directory /home/jupyter/ogawa_prediction/model/distil/2021-08-13/1 exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                     | Params\n",
      "-----------------------------------------------------------\n",
      "0 | model         | DistilBERTBaseClassifier | 67.5 M\n",
      "1 | loss_function | CrossEntropyLoss         | 0     \n",
      "2 | train_acc     | Accuracy                 | 0     \n",
      "3 | valid_acc     | Accuracy                 | 0     \n",
      "-----------------------------------------------------------\n",
      "67.1 M    Trainable params\n",
      "393 K     Non-trainable params\n",
      "67.5 M    Total params\n",
      "270.004   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d1911ee389469ebcc4034e9238ad28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/jupyter/.cache/pypoetry/virtualenvs/template-for-ai-pytorch-lightning-njAqaEcn-py3.7/lib/python3.7/site-packages/tensorboard/summary/writer/event_file_writer.py\", line 238, in run\n",
      "    self._record_writer.write(data)\n",
      "  File \"/home/jupyter/.cache/pypoetry/virtualenvs/template-for-ai-pytorch-lightning-njAqaEcn-py3.7/lib/python3.7/site-packages/tensorboard/summary/writer/record_writer.py\", line 40, in write\n",
      "    self._writer.write(header + header_crc + data + footer_crc)\n",
      "  File \"/home/jupyter/.cache/pypoetry/virtualenvs/template-for-ai-pytorch-lightning-njAqaEcn-py3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py\", line 531, in write\n",
      "    self.fs.append(self.filename, file_content, self.binary_mode)\n",
      "  File \"/home/jupyter/.cache/pypoetry/virtualenvs/template-for-ai-pytorch-lightning-njAqaEcn-py3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py\", line 154, in append\n",
      "    self._write(filename, file_content, \"ab\" if binary_mode else \"a\")\n",
      "  File \"/home/jupyter/.cache/pypoetry/virtualenvs/template-for-ai-pytorch-lightning-njAqaEcn-py3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py\", line 158, in _write\n",
      "    with io.open(filename, mode, encoding=encoding) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: b'/home/jupyter/ogawa_prediction/model/distil/2021-08-13/logs/default/version_1/events.out.tfevents.1628842842.foma-discribe-prediction-ogawa.19622.1'\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from wtfml.cross_validation.fold_generator import FoldGenerator\n",
    "from wtfml.data_loaders.nlp.classification import DistilBERTDataset\n",
    "from wtfml.data_loaders.pl_data_module.data_module import plDataModule\n",
    "from wtfml.engine.nlp.model import  DistilBERTBaseClassifier\n",
    "from wtfml.engine.pl_engine.DistilBERT_classification import DistilBERTClassificationPlEngine\n",
    "\n",
    "d_today = datetime.date.today()\n",
    "\n",
    "NUM_SPLIT = 1\n",
    "MAX_EPOCH = 10\n",
    "save_folder = \"./model/{}_distil\".format(d_today)\n",
    "train_data_path = \"./data/sample.csv\"\n",
    "\n",
    "\n",
    "data_df = pd.read_csv(train_data_path).dropna(subset=[\"description\"]).reset_index()\n",
    "target = data_df[\"target\"]\n",
    "input_data = data_df[\"description\"]\n",
    "\n",
    "fold_generator = FoldGenerator(\n",
    "    targets=target,\n",
    "    task=\"multiclass_classification\",\n",
    "    num_splits=NUM_SPLIT,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "for fold in range(NUM_SPLIT):\n",
    "    (\n",
    "        _,\n",
    "        _,\n",
    "        input_train,\n",
    "        input_val,\n",
    "        target_train,\n",
    "        target_val,\n",
    "    ) = fold_generator.get_fold(data=data_df, fold=fold)\n",
    "\n",
    "    train_dataset = DistilBERTDataset(\n",
    "        input_texts=input_train[\"description\"], target=target_train\n",
    "    )\n",
    "    val_dataset = DistilBERTDataset(\n",
    "        input_texts=input_val[\"description\"], target=target_val\n",
    "    )\n",
    "\n",
    "    data_module = plDataModule(\n",
    "        train_dataset=train_dataset, val_dataset=val_dataset, train_batch_size=64 #64\n",
    "    )\n",
    "\n",
    "    classification_model = DistilBERTBaseClassifier(num_classes=4)\n",
    "\n",
    "    pl_engine = DistilBERTClassificationPlEngine(\n",
    "        model=classification_model,\n",
    "        lr=1e-5,\n",
    "        max_epoch=MAX_EPOCH,\n",
    "    )\n",
    "\n",
    "    callbacks_path = os.path.join(save_folder, \"{}\".format(fold))\n",
    "\n",
    "    if not os.path.exists(callbacks_path):\n",
    "        os.makedirs(callbacks_path)\n",
    "    input_val.to_csv(\n",
    "        os.path.join(callbacks_path, \"valid_table.csv\")\n",
    "    )  # 度のデータをvalidationに利用したのかの記録\n",
    "\n",
    "    #\n",
    "    callbacks_loss = pl.callbacks.ModelCheckpoint(\n",
    "        dirpath=callbacks_path,\n",
    "        filename=\"{epoch}-{valid_loss:.4f}-{valid_acc:.4f}\",\n",
    "        monitor=\"valid_loss\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=1,\n",
    "        save_last=True,\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor = \"valid_loss\",\n",
    "        mode = \"min\",\n",
    "        patience=3\n",
    "    )\n",
    "    \n",
    "    tb_logger = pl_loggers.TensorBoardLogger(os.path.join(save_folder, \"logs/\"))\n",
    "    trainer = pl.Trainer(\n",
    "        gpus = 0,\n",
    "        max_epochs=MAX_EPOCH,\n",
    "        gradient_clip_val=0.5,\n",
    "        logger=tb_logger,\n",
    "        callbacks=[callbacks_loss, early_stopping],\n",
    "    )\n",
    "    trainer.fit(pl_engine, datamodule=data_module)\n",
    "\n",
    "    # memory leakingの対策\n",
    "    pl_engine.model.cpu()\n",
    "    for optimizer_metrics in trainer.optimizers[0].state.values():\n",
    "        for metric_name, metric in optimizer_metrics.items():\n",
    "            if torch.is_tensor(metric):\n",
    "                optimizer_metrics[metric_name] = metric.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae61940d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m76"
  },
  "interpreter": {
   "hash": "db14fcbd6854dcf50305cd491f1ed6d53c00927a3f051fbb5da322fe27a0478e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('ml': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
